{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_main = pd.read_csv(f'../datasets/tweets_full.csv')\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = \"GOOGL\"\n",
    "tweets = tweets_main[tweets_main[\"ticker_symbol\"] == company].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_body_v2(col):\n",
    "    import re\n",
    "\n",
    "    # usun urle\n",
    "    # usun hashtagi\n",
    "    # usun RT @username\n",
    "    pattern_url = r\"https?://[a-z0-9.]+/[?a-z0-9./-|]+\"\n",
    "    pattern_url_weak = r\"https?://[a-z0-9.]+\"\n",
    "    pattern_www = r\"www.[a-z0-9.]+/[?a-z0-9./-|]+\"\n",
    "    pattern_www_weak = r\"www.[a-z0-9.]+\"\n",
    "    pattern_hash_dolla = r\"[\\$#][a-z0-9.]+\"\n",
    "    pattern_retweet = r\"RT @[a-z0-9\\S.]+\"\n",
    "    pattern_username = r\"@[a-z0-9\\S.]+\"\n",
    "    pattern_scraper_artifacts = r\"[%-=_][\\w+-\\?\\&|]+\"\n",
    "\n",
    "    col = col.str.replace(pattern_url, \"\", col, flags=re.I)\n",
    "    col = col.str.replace(pattern_url_weak, \"\", col, flags=re.I)\n",
    "    col = col.str.replace(pattern_www, \"\", col, flags=re.I)\n",
    "    col = col.str.replace(pattern_www_weak, \"\", col, flags=re.I)\n",
    "    col = col.str.replace(pattern_hash_dolla, \"\", col, flags=re.I)\n",
    "    col = col.str.replace(pattern_retweet, \"\", col, flags=re.I)\n",
    "    col = col.str.replace(pattern_username, \"\", col, flags=re.I)\n",
    "    col = col.str.replace(pattern_scraper_artifacts, \"\", col, flags=re.I)\n",
    "    col = col.str.replace(\"…\", \"\", col, flags=re.I)\n",
    "\n",
    "\n",
    "    return \" \".join(col.split())\n",
    "\n",
    "def clean_body(col):\n",
    "    import re\n",
    "\n",
    "    # usun urle\n",
    "    # usun hashtagi\n",
    "    # usun RT @username\n",
    "    pattern_url = r\"https?://[a-z.]+/[?a-z0-9./]+\"\n",
    "    pattern_hash_dolla = r\"[\\$#][a-z.]+\"\n",
    "    #pattern_retweet = r\"RT @[a-z0-9\\S.]+\"\n",
    "    #pattern_username = r\"@[a-z0-9\\S.]+\"\n",
    "    #pattern_scraper_artifacts = r\"[%-=_][\\w+-\\?\\&|]+\"\n",
    "\n",
    "    col = col.str.replace(pattern_url, \"\", col, flags=re.I)\n",
    "    col = col.str.replace(pattern_hash_dolla, \"\", col, flags=re.I)\n",
    "    #col = col.str.replace(pattern_retweet, \"\", col, flags=re.I)\n",
    "    #col = col.str.replace(pattern_username, \"\", col, flags=re.I)\n",
    "    #col = col.str.replace(pattern_scraper_artifacts, \"\", col, flags=re.I)\n",
    "    #col = col.str.replace(\"…\", \"\", col, flags=re.I)\n",
    "\n",
    "    return col\n",
    "\n",
    "def convert_dict_keyval_to_col(dict, key):\n",
    "    new_col = []\n",
    "    for i in dict:\n",
    "        new_col.append(i[key])\n",
    "    return new_col\n",
    "\n",
    "\n",
    "def calc_weight(tweet):\n",
    "    retweets = tweet.retweet_num\n",
    "    likes = tweet.like_num\n",
    "    comms = tweet.comment_num\n",
    "    weight = 0\n",
    "    if tweet.retweet_num == 0:\n",
    "        weight = 1 + 0.05 * likes + 0.2 * comms\n",
    "    else:\n",
    "        weight = retweets * (1 + 0.05 * likes + 0.2 * comms)\n",
    "    return weight\n",
    "\n",
    "\n",
    "def calc_weight_2(tweet):\n",
    "    retweets = tweet.retweet_num\n",
    "    likes = tweet.like_num\n",
    "    comms = tweet.comment_num\n",
    "\n",
    "    weight = 1 + 0.5 * retweets + 0.05 * likes + 0.2 * comms\n",
    "    return weight\n",
    "\n",
    "\n",
    "def explore_weights(df, col):\n",
    "    print(df[df[col] == max(df[col])].body)\n",
    "    print(tweets[col].describe(percentiles=[0.05 * (i + 1) for i in range(19)]))\n",
    "\n",
    "\n",
    "def percentage_weights(df, col):\n",
    "    base = round(len(df.loc[df[col] == 1]) / len(df), 3) * 100\n",
    "    one_three = len(df.loc[(df[col] > 1) & (df[col] < 3)]) / len(tweets) * 100\n",
    "    three_five = len(df.loc[(df[col] > 3) & (df[col] < 10)]) / len(tweets) * 100\n",
    "\n",
    "    print(\"Worth 1 tweet:\", round(base, 3))\n",
    "    print(\"Worth 1 to 3 tweets:\", round(one_three, 3))\n",
    "    print(\"Worth 3 to 5 tweets:\", round(three_five, 3))\n",
    "    print(\"Total: \", round(base, 3) + round(one_three, 3) + round(three_five, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_body_v3(col):\n",
    "    import re\n",
    "\n",
    "    # usun urle\n",
    "    # usun hashtagi\n",
    "    # usun RT @username\n",
    "    pattern_url = r\"https?://[a-z0-9.]+/[?a-z0-9./-|]+\"\n",
    "    pattern_url_weak = r\"https?://[a-z0-9.]+\"\n",
    "    pattern_www = r\"www.[a-z0-9.]+/[?a-z0-9./-|]+\"\n",
    "    pattern_www_weak = r\"www.[a-z0-9.]+\"\n",
    "    pattern_hash_dolla = r\"[\\$#][a-z0-9.]+\"\n",
    "    pattern_retweet = r\"RT @[a-z0-9\\S.]+\"\n",
    "    pattern_username = r\"@[a-z0-9\\S.]+\"\n",
    "    pattern_scraper_artifacts = r\"[%-=_][\\w+-\\?\\&|]+\"\n",
    "\n",
    "    col = col.str.replace(re.compile(pattern_url, flags=re.I), \"\", regex=True)\n",
    "    col = col.str.replace(re.compile(pattern_url_weak, flags=re.I), \"\", regex=True)\n",
    "    col = col.str.replace(re.compile(pattern_www, flags=re.I), \"\", regex=True)\n",
    "    col = col.str.replace(re.compile(pattern_www_weak, flags=re.I), \"\", regex=True)\n",
    "    col = col.str.replace(re.compile(pattern_hash_dolla, flags=re.I), \"\", regex=True)\n",
    "    col = col.str.replace(re.compile(pattern_retweet, flags=re.I), \"\", regex=True)\n",
    "    col = col.str.replace(re.compile(pattern_username, flags=re.I), \"\", regex=True)\n",
    "    col = col.str.replace(re.compile(pattern_scraper_artifacts, flags=re.I), \"\", regex=True)\n",
    "    col = col.str.replace(\"…\", \"\")\n",
    "\n",
    "    return col.str.split().str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sentiment(df, to_preserve):\n",
    "    df = df.copy()\n",
    "    \n",
    "    sent = df[\"body\"].apply(analyzer.polarity_scores)\n",
    "\n",
    "    sentiment_val = pd.DataFrame()\n",
    "    sentiment_val[\"pos\"] = convert_dict_keyval_to_col(sent, \"pos\")\n",
    "    sentiment_val[\"neu\"] = convert_dict_keyval_to_col(sent, \"neu\")\n",
    "    sentiment_val[\"neg\"] = convert_dict_keyval_to_col(sent, \"neg\")\n",
    "    sentiment_val[\"comp\"] = convert_dict_keyval_to_col(sent, \"compound\")\n",
    "\n",
    "    for col in to_preserve:\n",
    "        sentiment_val[col] = df[col]\n",
    "\n",
    "    return sentiment_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = tweets.copy()\n",
    "clean.body = clean_body_v3(clean.body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = calc_sentiment(\n",
    "    tweets,\n",
    "    to_preserve=[\n",
    "        \"post_date\",\n",
    "        \"ticker_symbol\",\n",
    "        \"comment_num\",\n",
    "        \"retweet_num\",\n",
    "        \"like_num\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment[\"is_positive\"] = 0 \n",
    "sentiment.loc[sentiment[\"comp\"] > 0.05, \"is_positive\"] = 1\n",
    "\n",
    "sentiment[\"is_neutral\"] = 0 \n",
    "sentiment.loc[(sentiment[\"is_neutral\"] > -0.05) & (sentiment[\"is_neutral\"] < 0.05), \"is_neutral\"] = 1\n",
    "\n",
    "sentiment[\"is_negative\"] = 0 \n",
    "sentiment.loc[sentiment[\"comp\"] < -0.05, \"is_negative\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>neg</th>\n",
       "      <th>comp</th>\n",
       "      <th>post_date</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>is_positive</th>\n",
       "      <th>is_neutral</th>\n",
       "      <th>is_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321419</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>2019-11-10 15:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255815</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.4374</td>\n",
       "      <td>2018-10-20 20:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208134</th>\n",
       "      <td>0.176</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>2018-03-01 19:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64077</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2015-10-02 18:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62404</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2015-09-26 20:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137020</th>\n",
       "      <td>0.299</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>2017-01-20 11:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106536</th>\n",
       "      <td>0.197</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>2016-06-20 01:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2015-04-11 18:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39120</th>\n",
       "      <td>0.180</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>2015-07-01 09:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203439</th>\n",
       "      <td>0.202</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.6199</td>\n",
       "      <td>2018-02-02 21:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pos    neu    neg    comp            post_date ticker_symbol  \\\n",
       "321419  0.000  0.944  0.056 -0.1531  2019-11-10 15:00:00         GOOGL   \n",
       "255815  0.000  0.874  0.126 -0.4374  2018-10-20 20:00:00         GOOGL   \n",
       "208134  0.176  0.824  0.000  0.5994  2018-03-01 19:00:00         GOOGL   \n",
       "64077   0.000  1.000  0.000  0.0000  2015-10-02 18:00:00         GOOGL   \n",
       "62404   0.000  1.000  0.000  0.0000  2015-09-26 20:00:00         GOOGL   \n",
       "137020  0.299  0.642  0.059  0.6705  2017-01-20 11:00:00         GOOGL   \n",
       "106536  0.197  0.803  0.000  0.4019  2016-06-20 01:00:00         GOOGL   \n",
       "20636   0.000  1.000  0.000  0.0000  2015-04-11 18:00:00         GOOGL   \n",
       "39120   0.180  0.820  0.000  0.2960  2015-07-01 09:00:00         GOOGL   \n",
       "203439  0.202  0.798  0.000  0.6199  2018-02-02 21:00:00         GOOGL   \n",
       "\n",
       "        comment_num  retweet_num  like_num  is_positive  is_neutral  \\\n",
       "321419            0            0         0            0           1   \n",
       "255815            0            0         0            0           1   \n",
       "208134            0            0         0            1           1   \n",
       "64077             0            0         0            0           1   \n",
       "62404             0            0         0            0           1   \n",
       "137020            0            0         0            1           1   \n",
       "106536            0            4         9            1           1   \n",
       "20636             0            0         0            0           1   \n",
       "39120             0            0         0            1           1   \n",
       "203439            0            0         0            1           1   \n",
       "\n",
       "        is_negative  \n",
       "321419            1  \n",
       "255815            1  \n",
       "208134            0  \n",
       "64077             0  \n",
       "62404             0  \n",
       "137020            0  \n",
       "106536            0  \n",
       "20636             0  \n",
       "39120             0  \n",
       "203439            0  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#BREAKING Slow demand of iPhone X hits $AAPL as Analysts cut iPhone shipment forecast for 2018 in U.S. and Asia #DayAfterChristmas #stocks $GS $BAC $JPM $C $WFC $MS $PHK $BLK $NVDA $GOOGL $QCOM $AVGO $DB $RY $UBS $BCS $BMO $BX #BoxingDay #WallStreet #NYC'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.iloc[196214].body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Slow demand of iPhone X hits as Analysts cut iPhone shipment forecast for in U and Asia'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.iloc[196214].body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round down\n",
    "def round_down_hour(col):\n",
    "    try:\n",
    "        date, time = col.split(\" \")\n",
    "        time = f\"{time[0:2]}:00:00\"\n",
    "    except:\n",
    "        print(col)\n",
    "        raise Exception\n",
    "    return date + \" \" + time\n",
    "\n",
    "\n",
    "def aggregate_simple(df):\n",
    "    aggregated = pd.pivot_table(\n",
    "        df,\n",
    "        index=[\"post_date\"],\n",
    "        aggfunc={\n",
    "            \"pos\": [\"max\", \"min\", \"std\", \"mean\", \"median\", \"count\"],\n",
    "            \"neu\": [\"max\", \"min\", \"std\", \"mean\", \"median\"],\n",
    "            \"neg\": [\"max\", \"min\", \"std\", \"mean\", \"median\"],\n",
    "            \"comp\": [\"max\", \"min\", \"std\", \"mean\", \"median\"],\n",
    "            \"comment_num\": [\"sum\"],\n",
    "            \"retweet_num\": [\"sum\"],\n",
    "            \"like_num\": [\"sum\"],\n",
    "            \"is_positive\": [\"sum\"],\n",
    "            \"is_negative\": [\"sum\"],\n",
    "            \"is_neutral\": [\"sum\"],\n",
    "        },\n",
    "    ).reset_index()\n",
    "\n",
    "    aggregated.columns = [f\"{i}_{j}\" for i, j in aggregated.columns]\n",
    "    # clean columns\n",
    "    aggregated.rename(\n",
    "        columns={\n",
    "            f\"post_date_\": f\"post_date\",\n",
    "            f\"pos_count\": f\"count\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    return aggregated\n",
    "\n",
    "\n",
    "def reweight(df, weight):\n",
    "    cols = [\"pos\", \"neu\", \"neg\", \"comp\"]\n",
    "    for col in cols:\n",
    "        df[col] *= df[weight]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_total_tweets(df):\n",
    "    df[\"post_date\"] = df[\"post_date\"].apply(round_down_hour)\n",
    "    grouped = pd.pivot_table(\n",
    "        df,\n",
    "        index=[\"post_date\"],\n",
    "        aggfunc=[\"count\"],\n",
    "    ).reset_index()\n",
    "    grouped.columns = [f\"{i}_{j}\" for i, j in grouped.columns]\n",
    "    grouped.rename(\n",
    "        columns={\n",
    "            f\"post_date_\": f\"post_date\",\n",
    "            f\"count_body\": f\"total_count\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    return grouped[[\"post_date\", \"total_count\"]]\n",
    "\n",
    "\n",
    "def get_relative_count(df, df_total):\n",
    "\n",
    "    mrg = df.merge(df_total, how=\"left\", on=\"post_date\")\n",
    "    df[\"relative_count\"] = mrg[\"count\"] / mrg[\"total_count\"]\n",
    "    return df\n",
    "\n",
    "def normalize_polarity(df):\n",
    "    summed = df[\"is_negative_sum\"] + df[\"is_neutral_sum\"] + df[\"is_positive_sum\"]\n",
    "    df[\"is_negative_sum\"] /= summed\n",
    "    df[\"is_neutral_sum\"] /= summed\n",
    "    df[\"is_positive_sum\"] /= summed\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_date</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             post_date  total_count\n",
       "0  2015-01-01 01:00:00           50\n",
       "1  2015-01-01 02:00:00           38\n",
       "2  2015-01-01 03:00:00           29\n",
       "3  2015-01-01 04:00:00           30\n",
       "4  2015-01-01 05:00:00           24"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tweets = get_total_tweets(tweets_main)\n",
    "total_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment[\"post_date\"] = sentiment[\"post_date\"].apply(round_down_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment_w1 = reweight(sentiment.copy(), \"weight\")\n",
    "#sentiment_w1 = sentiment_w1.drop([\"weight\", \"weight2\"], axis=1)\n",
    "#sentiment_w1 = sentiment_w1.drop([\"weight\"], axis=1)\n",
    "#sentiment_w1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment_w2 = reweight(sentiment.copy(), \"weight2\")\n",
    "#sentiment_w2 = sentiment_w2.drop([\"weight\", \"weight2\"], axis=1)\n",
    "#sentiment_w2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment_no_weight = sentiment.drop([\"weight\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_w1 = aggregate_simple(sentiment_w1)\n",
    "# agg_w1 = get_relative_count(agg_w1, total_tweets)\n",
    "# agg_w1 = agg_w1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_w1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>neg</th>\n",
       "      <th>comp</th>\n",
       "      <th>post_date</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>is_positive</th>\n",
       "      <th>is_neutral</th>\n",
       "      <th>is_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pos    neu  neg    comp            post_date ticker_symbol  comment_num  \\\n",
       "7  0.565  0.435  0.0  0.5994  2015-01-01 05:00:00         GOOGL            0   \n",
       "\n",
       "   retweet_num  like_num  is_positive  is_neutral  is_negative  \n",
       "7            0         0            1           1            0  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment[sentiment[\"post_date\"] == \"2015-01-01 05:00:00\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_no_w = aggregate_simple(sentiment)\n",
    "agg_no_w = get_relative_count(agg_no_w, total_tweets)\n",
    "# std is NaN when count is 1\n",
    "agg_no_w = agg_no_w.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_date</th>\n",
       "      <th>comment_num_sum</th>\n",
       "      <th>comp_max</th>\n",
       "      <th>comp_mean</th>\n",
       "      <th>comp_median</th>\n",
       "      <th>comp_min</th>\n",
       "      <th>comp_std</th>\n",
       "      <th>is_negative_sum</th>\n",
       "      <th>is_neutral_sum</th>\n",
       "      <th>is_positive_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>neu_min</th>\n",
       "      <th>neu_std</th>\n",
       "      <th>count</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>pos_mean</th>\n",
       "      <th>pos_median</th>\n",
       "      <th>pos_min</th>\n",
       "      <th>pos_std</th>\n",
       "      <th>retweet_num_sum</th>\n",
       "      <th>relative_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.08895</td>\n",
       "      <td>-0.5766</td>\n",
       "      <td>0.466565</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.101668</td>\n",
       "      <td>4</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.07375</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090223</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.59940</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.56500</td>\n",
       "      <td>0.5650</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 07:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             post_date  comment_num_sum  comp_max  comp_mean  comp_median  \\\n",
       "0  2015-01-01 01:00:00                0    0.0000     0.0000      0.00000   \n",
       "1  2015-01-01 02:00:00                0    0.5423     0.0359      0.08895   \n",
       "2  2015-01-01 03:00:00                0    0.0000     0.0000      0.00000   \n",
       "3  2015-01-01 05:00:00                0    0.5994     0.5994      0.59940   \n",
       "4  2015-01-01 07:00:00                0    0.0000     0.0000      0.00000   \n",
       "\n",
       "   comp_min  comp_std  is_negative_sum  is_neutral_sum  is_positive_sum  ...  \\\n",
       "0    0.0000  0.000000         0.000000        1.000000         0.000000  ...   \n",
       "1   -0.5766  0.466565         0.142857        0.571429         0.285714  ...   \n",
       "2    0.0000  0.000000         0.000000        1.000000         0.000000  ...   \n",
       "3    0.5994  0.000000         0.000000        0.500000         0.500000  ...   \n",
       "4    0.0000  0.000000         0.000000        1.000000         0.000000  ...   \n",
       "\n",
       "   neu_min   neu_std  count  pos_max  pos_mean  pos_median  pos_min   pos_std  \\\n",
       "0    1.000  0.000000      1    0.000   0.00000      0.0000    0.000  0.000000   \n",
       "1    0.777  0.101668      4    0.184   0.07375      0.0555    0.000  0.090223   \n",
       "2    1.000  0.000000      2    0.000   0.00000      0.0000    0.000  0.000000   \n",
       "3    0.435  0.000000      1    0.565   0.56500      0.5650    0.565  0.000000   \n",
       "4    1.000  0.000000      3    0.000   0.00000      0.0000    0.000  0.000000   \n",
       "\n",
       "   retweet_num_sum  relative_count  \n",
       "0                2        0.020000  \n",
       "1                0        0.105263  \n",
       "2                0        0.068966  \n",
       "3                0        0.041667  \n",
       "4                0        0.166667  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_no_w = normalize_polarity(agg_no_w)\n",
    "agg_no_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agg_w1.to_csv(f\"../datasets/v3/more_cols/w1/{company}.csv\", index=False)\n",
    "agg_no_w.to_csv(f\"../datasets/v3/senti/{company}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1dd0381d1fc2fb15dda0c9601b2866ce5a466e54b3f253773e8ed097d13694fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
