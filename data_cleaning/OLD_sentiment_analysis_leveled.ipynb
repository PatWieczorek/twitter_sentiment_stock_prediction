{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_main = pd.read_csv(f'../datasets/tweets_full.csv')\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = \"GOOGL\"\n",
    "tweets = tweets_main[tweets_main[\"ticker_symbol\"] == company]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>550447998577426433</td>\n",
       "      <td>2015-01-01 01:26:44</td>\n",
       "      <td>2014 The Year in Review (Part II - THE END) ht...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>550461555423584257</td>\n",
       "      <td>2015-01-01 02:20:36</td>\n",
       "      <td>Prediction: $TWTR $GRPN $YELP are acquired as ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>550462670353494016</td>\n",
       "      <td>2015-01-01 02:25:02</td>\n",
       "      <td>Prediction: PayPal post-spinoff and $PAY are n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>550466497655877633</td>\n",
       "      <td>2015-01-01 02:40:14</td>\n",
       "      <td>Trailing Stop taken out on my $GOOGL #trade ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>550471417754845184</td>\n",
       "      <td>2015-01-01 02:59:47</td>\n",
       "      <td>#SENTISHIFTUP $X $T $GOOGL $AMRN $UPIP $CNAT $...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id            post_date  \\\n",
       "30  550447998577426433  2015-01-01 01:26:44   \n",
       "59  550461555423584257  2015-01-01 02:20:36   \n",
       "62  550462670353494016  2015-01-01 02:25:02   \n",
       "72  550466497655877633  2015-01-01 02:40:14   \n",
       "87  550471417754845184  2015-01-01 02:59:47   \n",
       "\n",
       "                                                 body  comment_num  \\\n",
       "30  2014 The Year in Review (Part II - THE END) ht...            0   \n",
       "59  Prediction: $TWTR $GRPN $YELP are acquired as ...            0   \n",
       "62  Prediction: PayPal post-spinoff and $PAY are n...            0   \n",
       "72  Trailing Stop taken out on my $GOOGL #trade ta...            0   \n",
       "87  #SENTISHIFTUP $X $T $GOOGL $AMRN $UPIP $CNAT $...            0   \n",
       "\n",
       "    retweet_num  like_num ticker_symbol  \n",
       "30            2         2         GOOGL  \n",
       "59            0         1         GOOGL  \n",
       "62            0         0         GOOGL  \n",
       "72            0         0         GOOGL  \n",
       "87            0         0         GOOGL  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.sort_values(\"post_date\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_body(col):\n",
    "    import re\n",
    "\n",
    "    # usun urle\n",
    "    # usun hashtagi\n",
    "    pattern_url = r\"https?://[a-z.]+/[?a-z0-9./]+\"\n",
    "    pattern_hash = r\"#\"\n",
    "    col = re.sub(pattern_url, \"\", col, flags=re.I)\n",
    "    col = re.sub(pattern_hash, \"\", col, flags=re.I)\n",
    "\n",
    "    return col\n",
    "\n",
    "\n",
    "def convert_dict_keyval_to_col(dict, key):\n",
    "    new_col = []\n",
    "    for i in dict:\n",
    "        new_col.append(i[key])\n",
    "    return new_col\n",
    "\n",
    "\n",
    "def calc_sentiment(df, other_cols):\n",
    "    df = df.copy()\n",
    "    sent = df[\"body\"].apply(analyzer.polarity_scores)\n",
    "\n",
    "    sentiment_val = pd.DataFrame()\n",
    "    sentiment_val[\"pos\"] = convert_dict_keyval_to_col(sent, \"pos\")\n",
    "    sentiment_val[\"neu\"] = convert_dict_keyval_to_col(sent, \"neu\")\n",
    "    sentiment_val[\"neg\"] = convert_dict_keyval_to_col(sent, \"neg\")\n",
    "    sentiment_val[\"comp\"] = convert_dict_keyval_to_col(sent, \"compound\")\n",
    "\n",
    "    for col in other_cols:\n",
    "        sentiment_val[col] = df[col]\n",
    "\n",
    "    return sentiment_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean = tweets['body'].apply(clean_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_has_comm = tweets[tweets[\"comment_num\"] > 0].reset_index(drop=True)\n",
    "tweets_has_rtwts = tweets[tweets[\"retweet_num\"] > 0].reset_index(drop=True)\n",
    "tweets_has_likes = tweets[tweets[\"like_num\"] > 0].reset_index(drop=True)\n",
    "tweets_has_all = tweets[\n",
    "    (tweets[\"like_num\"] > 0) & (tweets[\"retweet_num\"] > 0) & (tweets[\"comment_num\"] > 0)\n",
    "].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_tweet_has_all = tweets.tweet_id.isin(tweets_has_all.tweet_id)\n",
    "tweets_rest = tweets[~is_tweet_has_all].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(tweets_rest)+len(tweets_has_all) == len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550759232455585792</td>\n",
       "      <td>2015-01-01 22:03:28</td>\n",
       "      <td>@downsidecapital $FB can't afford it, so $GOOG...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550847677227749376</td>\n",
       "      <td>2015-01-02 03:54:55</td>\n",
       "      <td>@traderstewie what's ur trade direction call o...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>551037180706295809</td>\n",
       "      <td>2015-01-02 16:27:56</td>\n",
       "      <td>@sassyoptions $aapl $googl not trying to be be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>551105886337654784</td>\n",
       "      <td>2015-01-02 21:00:57</td>\n",
       "      <td>@downsidecapital @taralach  From a BS perspect...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551211352703135744</td>\n",
       "      <td>2015-01-03 04:00:02</td>\n",
       "      <td>2015 Stocks to Love and Hate http://optionmill...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id            post_date  \\\n",
       "0  550759232455585792  2015-01-01 22:03:28   \n",
       "1  550847677227749376  2015-01-02 03:54:55   \n",
       "2  551037180706295809  2015-01-02 16:27:56   \n",
       "3  551105886337654784  2015-01-02 21:00:57   \n",
       "4  551211352703135744  2015-01-03 04:00:02   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  @downsidecapital $FB can't afford it, so $GOOG...            1   \n",
       "1  @traderstewie what's ur trade direction call o...            2   \n",
       "2  @sassyoptions $aapl $googl not trying to be be...            1   \n",
       "3  @downsidecapital @taralach  From a BS perspect...            1   \n",
       "4  2015 Stocks to Love and Hate http://optionmill...            1   \n",
       "\n",
       "   retweet_num  like_num ticker_symbol  \n",
       "0            0         1         GOOGL  \n",
       "1            0         0         GOOGL  \n",
       "2            0         0         GOOGL  \n",
       "3            0         0         GOOGL  \n",
       "4            2         9         GOOGL  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_has_comm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_comms = calc_sentiment(tweets_has_comm, [\"post_date\", \"ticker_symbol\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_rtwts = calc_sentiment(tweets_has_rtwts, [\"post_date\", \"ticker_symbol\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_likes = calc_sentiment(tweets_has_likes, [\"post_date\", \"ticker_symbol\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_all = calc_sentiment(tweets_has_all, [\"post_date\", \"ticker_symbol\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = calc_sentiment(tweets_rest, [\"post_date\", \"ticker_symbol\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "\n",
    "1. Group by hour\n",
    "2. Merge tables using proper naming \n",
    "3. Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round down\n",
    "def round_down_hour(col):\n",
    "    try:\n",
    "        date, time = col.split(\" \")\n",
    "        time = f\"{time[0:2]}:00:00\"\n",
    "    except:\n",
    "        print(col)\n",
    "        raise Exception\n",
    "    return date + \" \" + time\n",
    "\n",
    "\n",
    "def aggregate(df, name):\n",
    "    aggregated = pd.pivot_table(\n",
    "        df,\n",
    "        index=[\"post_date\"],\n",
    "        aggfunc=[\"max\", \"min\", \"std\", \"mean\", \"median\", \"count\"],\n",
    "    ).reset_index()\n",
    "\n",
    "    aggregated.columns = [f\"{i}_{j}_{name}\" for i, j in aggregated.columns]\n",
    "    # clean columns\n",
    "    aggregated.rename(\n",
    "        columns={\n",
    "            f\"post_date__{name}\": f\"post_date\",\n",
    "            f\"count_pos_{name}\": f\"count_{name}\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # drop useless\n",
    "    aggregated = aggregated.drop(\n",
    "        [\n",
    "            f\"count_neg_{name}\",\n",
    "            f\"count_neu_{name}\",\n",
    "            f\"count_comp_{name}\",\n",
    "            f\"min_ticker_symbol_{name}\",\n",
    "            f\"count_ticker_symbol_{name}\",\n",
    "            f\"max_ticker_symbol_{name}\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return aggregated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_comms.post_date = has_comms.post_date.apply(round_down_hour)\n",
    "has_rtwts.post_date = has_rtwts.post_date.apply(round_down_hour)\n",
    "has_likes.post_date = has_likes.post_date.apply(round_down_hour)\n",
    "has_all.post_date = has_all.post_date.apply(round_down_hour)\n",
    "rest.post_date = rest.post_date.apply(round_down_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "comms_agg = aggregate(has_comms, \"comms\")\n",
    "rtwts_agg = aggregate(has_rtwts, \"rtwts\")\n",
    "likes_agg = aggregate(has_likes, \"likes\")\n",
    "all_agg = aggregate(has_all, \"all\")\n",
    "rest_agg = aggregate(rest, \"rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sentiment = comms_agg\n",
    "for df in [rtwts_agg, likes_agg, all_agg, rest_agg]:\n",
    "    merged_sentiment = merged_sentiment.merge(df, how=\"outer\", on=\"post_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sentiment.to_csv(f\"../datasets/sentiment_leveled/{company}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1dd0381d1fc2fb15dda0c9601b2866ce5a466e54b3f253773e8ed097d13694fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
